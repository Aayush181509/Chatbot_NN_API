{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "srTr1HJlVExU",
    "outputId": "cfaefd87-f76e-4ebe-cf19-4bc173d5b0d2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting nltk\n",
      "  Downloading nltk-3.8.1-py3-none-any.whl (1.5 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: click in /home/student/.anaconda3/envs/vfcenv/lib/python3.9/site-packages (from nltk) (8.1.3)\n",
      "Requirement already satisfied: joblib in /home/student/.anaconda3/envs/vfcenv/lib/python3.9/site-packages (from nltk) (1.2.0)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /home/student/.anaconda3/envs/vfcenv/lib/python3.9/site-packages (from nltk) (2023.6.3)\n",
      "Requirement already satisfied: tqdm in /home/student/.anaconda3/envs/vfcenv/lib/python3.9/site-packages (from nltk) (4.65.0)\n",
      "Installing collected packages: nltk\n",
      "Successfully installed nltk-3.8.1\n",
      "Requirement already satisfied: torch in /home/student/.anaconda3/envs/vfcenv/lib/python3.9/site-packages (2.0.1)\n",
      "Requirement already satisfied: filelock in /home/student/.anaconda3/envs/vfcenv/lib/python3.9/site-packages (from torch) (3.12.2)\n",
      "Requirement already satisfied: typing-extensions in /home/student/.anaconda3/envs/vfcenv/lib/python3.9/site-packages (from torch) (4.4.0)\n",
      "Requirement already satisfied: sympy in /home/student/.anaconda3/envs/vfcenv/lib/python3.9/site-packages (from torch) (1.12)\n",
      "Requirement already satisfied: networkx in /home/student/.anaconda3/envs/vfcenv/lib/python3.9/site-packages (from torch) (3.1)\n",
      "Requirement already satisfied: jinja2 in /home/student/.anaconda3/envs/vfcenv/lib/python3.9/site-packages (from torch) (3.1.2)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu11==11.7.99 in /home/student/.anaconda3/envs/vfcenv/lib/python3.9/site-packages (from torch) (11.7.99)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu11==11.7.99 in /home/student/.anaconda3/envs/vfcenv/lib/python3.9/site-packages (from torch) (11.7.99)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu11==11.7.101 in /home/student/.anaconda3/envs/vfcenv/lib/python3.9/site-packages (from torch) (11.7.101)\n",
      "Requirement already satisfied: nvidia-cudnn-cu11==8.5.0.96 in /home/student/.anaconda3/envs/vfcenv/lib/python3.9/site-packages (from torch) (8.5.0.96)\n",
      "Requirement already satisfied: nvidia-cublas-cu11==11.10.3.66 in /home/student/.anaconda3/envs/vfcenv/lib/python3.9/site-packages (from torch) (11.10.3.66)\n",
      "Requirement already satisfied: nvidia-cufft-cu11==10.9.0.58 in /home/student/.anaconda3/envs/vfcenv/lib/python3.9/site-packages (from torch) (10.9.0.58)\n",
      "Requirement already satisfied: nvidia-curand-cu11==10.2.10.91 in /home/student/.anaconda3/envs/vfcenv/lib/python3.9/site-packages (from torch) (10.2.10.91)\n",
      "Requirement already satisfied: nvidia-cusolver-cu11==11.4.0.1 in /home/student/.anaconda3/envs/vfcenv/lib/python3.9/site-packages (from torch) (11.4.0.1)\n",
      "Requirement already satisfied: nvidia-cusparse-cu11==11.7.4.91 in /home/student/.anaconda3/envs/vfcenv/lib/python3.9/site-packages (from torch) (11.7.4.91)\n",
      "Requirement already satisfied: nvidia-nccl-cu11==2.14.3 in /home/student/.anaconda3/envs/vfcenv/lib/python3.9/site-packages (from torch) (2.14.3)\n",
      "Requirement already satisfied: nvidia-nvtx-cu11==11.7.91 in /home/student/.anaconda3/envs/vfcenv/lib/python3.9/site-packages (from torch) (11.7.91)\n",
      "Requirement already satisfied: triton==2.0.0 in /home/student/.anaconda3/envs/vfcenv/lib/python3.9/site-packages (from torch) (2.0.0)\n",
      "Requirement already satisfied: setuptools in /home/student/.anaconda3/envs/vfcenv/lib/python3.9/site-packages (from nvidia-cublas-cu11==11.10.3.66->torch) (67.8.0)\n",
      "Requirement already satisfied: wheel in /home/student/.anaconda3/envs/vfcenv/lib/python3.9/site-packages (from nvidia-cublas-cu11==11.10.3.66->torch) (0.38.4)\n",
      "Requirement already satisfied: cmake in /home/student/.anaconda3/envs/vfcenv/lib/python3.9/site-packages (from triton==2.0.0->torch) (3.26.4)\n",
      "Requirement already satisfied: lit in /home/student/.anaconda3/envs/vfcenv/lib/python3.9/site-packages (from triton==2.0.0->torch) (16.0.6)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/student/.anaconda3/envs/vfcenv/lib/python3.9/site-packages (from jinja2->torch) (2.1.1)\n",
      "Requirement already satisfied: mpmath>=0.19 in /home/student/.anaconda3/envs/vfcenv/lib/python3.9/site-packages (from sympy->torch) (1.3.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install nltk\n",
    "!pip install torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "SJ4ssXbEWlae",
    "outputId": "c7b70193-82ae-4b44-fc8e-97349cfde691"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/student/nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')\n",
    "\n",
    "from nltk.stem.lancaster import LancasterStemmer\n",
    "stemmer = LancasterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "sjS9w-LgWlfu"
   },
   "outputs": [],
   "source": [
    "def tokenize(sentence):\n",
    "  return nltk.word_tokenize(sentence)\n",
    "\n",
    "def stem(word):\n",
    "  return stemmer.stem(word.lower())\n",
    "\n",
    "def bag_of_words(tokenized_sentence, all_words):\n",
    "   tokenized_sentence=[stem(w) for w in tokenized_sentence]\n",
    "   bag=np.zeros(len(all_words), dtype=np.float32)\n",
    "   for idx, w in enumerate(all_words):\n",
    "    if w in tokenized_sentence:\n",
    "      bag[idx]=1.0\n",
    "   return bag\n",
    "\n",
    "# a=['hello','how','are','you']\n",
    "# words=['hi','hello','how','you','bye','thank']\n",
    "# bog=bag_of_words(a,words)\n",
    "# print(bog)\n",
    "\n",
    "\n",
    "# a=\"How are you\"\n",
    "# print(a)\n",
    "# a=tokenize(a)\n",
    "# print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "OTF-k6dmX1F9",
    "outputId": "ff780e13-2875-49a5-e019-337b5d3b89a9"
   },
   "outputs": [],
   "source": [
    "# words=[\"organize\",\"organizes\",\"organizing\"]\n",
    "# stemmed_words=[stem(w)for w in words]\n",
    "# print(stemmed_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "Ht_rTGPC9ODB"
   },
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 69
    },
    "id": "GTuVLTKCY1bt",
    "outputId": "f839a19b-417b-49ee-f755-2ef9c5640f96"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "     <input type=\"file\" id=\"files-22cc466a-4d96-4dc5-8e13-8ca8831aa7cb\" name=\"files[]\" multiple disabled\n",
       "        style=\"border:none\" />\n",
       "     <output id=\"result-22cc466a-4d96-4dc5-8e13-8ca8831aa7cb\">\n",
       "      Upload widget is only available when the cell has been executed in the\n",
       "      current browser session. Please rerun this cell to enable.\n",
       "      </output>\n",
       "      <script>// Copyright 2017 Google LLC\n",
       "//\n",
       "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
       "// you may not use this file except in compliance with the License.\n",
       "// You may obtain a copy of the License at\n",
       "//\n",
       "//      http://www.apache.org/licenses/LICENSE-2.0\n",
       "//\n",
       "// Unless required by applicable law or agreed to in writing, software\n",
       "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
       "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
       "// See the License for the specific language governing permissions and\n",
       "// limitations under the License.\n",
       "\n",
       "/**\n",
       " * @fileoverview Helpers for google.colab Python module.\n",
       " */\n",
       "(function(scope) {\n",
       "function span(text, styleAttributes = {}) {\n",
       "  const element = document.createElement('span');\n",
       "  element.textContent = text;\n",
       "  for (const key of Object.keys(styleAttributes)) {\n",
       "    element.style[key] = styleAttributes[key];\n",
       "  }\n",
       "  return element;\n",
       "}\n",
       "\n",
       "// Max number of bytes which will be uploaded at a time.\n",
       "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
       "\n",
       "function _uploadFiles(inputId, outputId) {\n",
       "  const steps = uploadFilesStep(inputId, outputId);\n",
       "  const outputElement = document.getElementById(outputId);\n",
       "  // Cache steps on the outputElement to make it available for the next call\n",
       "  // to uploadFilesContinue from Python.\n",
       "  outputElement.steps = steps;\n",
       "\n",
       "  return _uploadFilesContinue(outputId);\n",
       "}\n",
       "\n",
       "// This is roughly an async generator (not supported in the browser yet),\n",
       "// where there are multiple asynchronous steps and the Python side is going\n",
       "// to poll for completion of each step.\n",
       "// This uses a Promise to block the python side on completion of each step,\n",
       "// then passes the result of the previous step as the input to the next step.\n",
       "function _uploadFilesContinue(outputId) {\n",
       "  const outputElement = document.getElementById(outputId);\n",
       "  const steps = outputElement.steps;\n",
       "\n",
       "  const next = steps.next(outputElement.lastPromiseValue);\n",
       "  return Promise.resolve(next.value.promise).then((value) => {\n",
       "    // Cache the last promise value to make it available to the next\n",
       "    // step of the generator.\n",
       "    outputElement.lastPromiseValue = value;\n",
       "    return next.value.response;\n",
       "  });\n",
       "}\n",
       "\n",
       "/**\n",
       " * Generator function which is called between each async step of the upload\n",
       " * process.\n",
       " * @param {string} inputId Element ID of the input file picker element.\n",
       " * @param {string} outputId Element ID of the output display.\n",
       " * @return {!Iterable<!Object>} Iterable of next steps.\n",
       " */\n",
       "function* uploadFilesStep(inputId, outputId) {\n",
       "  const inputElement = document.getElementById(inputId);\n",
       "  inputElement.disabled = false;\n",
       "\n",
       "  const outputElement = document.getElementById(outputId);\n",
       "  outputElement.innerHTML = '';\n",
       "\n",
       "  const pickedPromise = new Promise((resolve) => {\n",
       "    inputElement.addEventListener('change', (e) => {\n",
       "      resolve(e.target.files);\n",
       "    });\n",
       "  });\n",
       "\n",
       "  const cancel = document.createElement('button');\n",
       "  inputElement.parentElement.appendChild(cancel);\n",
       "  cancel.textContent = 'Cancel upload';\n",
       "  const cancelPromise = new Promise((resolve) => {\n",
       "    cancel.onclick = () => {\n",
       "      resolve(null);\n",
       "    };\n",
       "  });\n",
       "\n",
       "  // Wait for the user to pick the files.\n",
       "  const files = yield {\n",
       "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
       "    response: {\n",
       "      action: 'starting',\n",
       "    }\n",
       "  };\n",
       "\n",
       "  cancel.remove();\n",
       "\n",
       "  // Disable the input element since further picks are not allowed.\n",
       "  inputElement.disabled = true;\n",
       "\n",
       "  if (!files) {\n",
       "    return {\n",
       "      response: {\n",
       "        action: 'complete',\n",
       "      }\n",
       "    };\n",
       "  }\n",
       "\n",
       "  for (const file of files) {\n",
       "    const li = document.createElement('li');\n",
       "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
       "    li.append(span(\n",
       "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
       "        `last modified: ${\n",
       "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
       "                                    'n/a'} - `));\n",
       "    const percent = span('0% done');\n",
       "    li.appendChild(percent);\n",
       "\n",
       "    outputElement.appendChild(li);\n",
       "\n",
       "    const fileDataPromise = new Promise((resolve) => {\n",
       "      const reader = new FileReader();\n",
       "      reader.onload = (e) => {\n",
       "        resolve(e.target.result);\n",
       "      };\n",
       "      reader.readAsArrayBuffer(file);\n",
       "    });\n",
       "    // Wait for the data to be ready.\n",
       "    let fileData = yield {\n",
       "      promise: fileDataPromise,\n",
       "      response: {\n",
       "        action: 'continue',\n",
       "      }\n",
       "    };\n",
       "\n",
       "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
       "    let position = 0;\n",
       "    do {\n",
       "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
       "      const chunk = new Uint8Array(fileData, position, length);\n",
       "      position += length;\n",
       "\n",
       "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
       "      yield {\n",
       "        response: {\n",
       "          action: 'append',\n",
       "          file: file.name,\n",
       "          data: base64,\n",
       "        },\n",
       "      };\n",
       "\n",
       "      let percentDone = fileData.byteLength === 0 ?\n",
       "          100 :\n",
       "          Math.round((position / fileData.byteLength) * 100);\n",
       "      percent.textContent = `${percentDone}% done`;\n",
       "\n",
       "    } while (position < fileData.byteLength);\n",
       "  }\n",
       "\n",
       "  // All done.\n",
       "  yield {\n",
       "    response: {\n",
       "      action: 'complete',\n",
       "    }\n",
       "  };\n",
       "}\n",
       "\n",
       "scope.google = scope.google || {};\n",
       "scope.google.colab = scope.google.colab || {};\n",
       "scope.google.colab._files = {\n",
       "  _uploadFiles,\n",
       "  _uploadFilesContinue,\n",
       "};\n",
       "})(self);\n",
       "</script> "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving intents.json to intents.json\n"
     ]
    }
   ],
   "source": [
    "from google.colab import files\n",
    "uploaded=files.upload()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ozNM4hrxRDZG",
    "outputId": "19a4147b-2a87-48ae-8e3f-ec986feed66b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'intents': [{'tag': 'greeting', 'patterns': ['Hi', 'How are you', 'Is anyone there?', 'Hello', 'Good day'], 'responses': ['Hello, thanks for visiting', 'Good to see you again', 'Hi there, how can I help?'], 'context_set': ''}, {'tag': 'goodbye', 'patterns': ['Bye', 'See you later', 'Goodbye'], 'responses': ['See you later, thanks for visiting', 'Have a nice day', 'Bye! Come back again soon.']}, {'tag': 'thanks', 'patterns': ['Thanks', 'Thank you', \"That's helpful\"], 'responses': ['Happy to help!', 'Any time!', 'My pleasure']}, {'tag': 'hours', 'patterns': ['What hours are you open?', 'What are your hours?', 'When are you open?'], 'responses': [\"We're open every day 9am-9pm\", 'Our hours are 9am-9pm every day']}, {'tag': 'payments', 'patterns': ['Do you take online payments?', 'Are you cash only?', 'What are the means of payment?'], 'responses': ['We accept payment via khalti', 'We accept cash as well as online payment']}, {'tag': 'open_today', 'patterns': ['Are you open today?', 'When do you open today?', 'What are your hours today?'], 'responses': [\"We're open all day every day\"]}, {'tag': 'create_account', 'patterns': ['How can i create my account?', 'How to register?', \"I don't have an online account\", 'I need help creating an online account'], 'responses': ['Click login and you will find register button. After that provide us your required information and your account will be created']}, {'tag': 'buy_books', 'patterns': ['How to buy books?', 'How can i buy?', 'How to purchase?', 'What are the steps to buy books?'], 'responses': ['Click buy on your desired books. Fill out the necessary details and make payments. You will then recieve a receipt.']}, {'tag': 'account', 'patterns': ['Can i buy books without registering?', 'Do i need to create an account to purchase', \"Can't i buy books without online account?\"], 'responses': ['You need to be registered into our system to purchase books', 'You must have an account to buy', 'You must be logged in with your account to buy books.']}, {'tag': 'Cancel_order', 'patterns': ['Cancel my order', 'Can i cancel my order?', 'How can i cancel my order', 'I need help cancelling my order?', 'I need help for cancelling my order'], 'responses': ['For order cancellation, please contact us through the phone number.']}, {'tag': 'Contact_customer_service', 'patterns': ['How can i reach the customer service?', 'I want to talk ', 'can you tell me the email or phone number to contact customer support, please??', 'how to talk to Client Service', 'i want to know if there is a free phone number to contact customer service', 'I want information, help me talk to Customer Support', 'I want information and I want to send an email to Customer Support', 'please, can u find information about the email address to contact Customer Service?', 'Give me your contact information.'], 'responses': ['You can reach the customer service through either email(XXX@gmail.com or phone number(XXXXXXXXXX)']}, {'tag': 'Delivery_options', 'patterns': ['How to receive my order?', 'What are the delivery options?', 'Do you carry out home delivery?', 'How to pickup my ordered items?', 'i want to know if there is a free phone number to contact customer service', 'Can i get my item to be home delivered?', 'I want my books delivered at my home'], 'responses': ['We carryout home delivery as well as pickups. For home delivery extra charges will be added']}, {'tag': 'Delivery_period', 'patterns': ['How long will it take for my order to be delivered?', 'When will my book arrive?', 'Tell me the delivery period', 'Can you tell me how soon can i expect my books to arrive?', 'What is your delivery period?', 'How soon will i have my books delivered?'], 'responses': ['Our delivery period is usually 2-3 days. If it is taking longer than that, please contact the customer support']}, {'tag': 'Blog', 'patterns': ['Can i write my original articles on this website?', 'What can you do in the blog section?', 'What is the blog section for?', 'Is there any feature of writing original contents in this website?'], 'responses': ['Blog section is for writing original articles and contents to share to the public.']}, {'tag': 'Blog_direction', 'patterns': ['How to write my original articles on this website?', 'How to use the blog feature?', 'How to write my blogs?', 'Publish an article or blog.'], 'responses': ['You can write your content by going to the blog section. You need to be logged in to publish your content. In the blog section you can write and publish your article.']}, {'tag': 'Complaint', 'patterns': ['How to report my complaints?', 'I want to lodge my complaint', 'I have few criticisms.', \"I didn't like your service.\", 'I am not happy with the service', \"It seems i can't place an order\", 'There is a problem while writing blogs.', 'I am having payment issues.'], 'responses': ['Sorry for the inconvenience. You can lodge your complaint by contacting us through email and phone number. We will try to do better next time.']}, {'tag': 'Book_Review', 'patterns': ['Can i place a review on the book?', 'I like the books you have.', 'I want to leave star reviews.'], 'responses': ['You can place your review on the books you like with star ratings.']}, {'tag': 'Blog_Review', 'patterns': ['Can i place a review on the article?', 'I like the articles published on your website.', 'Can i give my genuine suggestions to the blog writers?'], 'responses': ['You can place your review on the blog you like by leaving your reviews in the comment section.']}, {'tag': 'Refund', 'patterns': ['Can i get refund?', 'What about refund.', 'What are your refund policies?'], 'responses': ['For refund contact us directly through email or phone number.']}]}\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "with open('intents.json','r') as i:\n",
    "  intents=json.load(i)\n",
    "print(intents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "7S6cPpdMbzfJ"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "eyVT87O9GuHk"
   },
   "outputs": [],
   "source": [
    "class NeuralNet(nn.Module):\n",
    "  def __init__(self,input_size,hidden_size,num_classes):\n",
    "    super(NeuralNet,self).__init__()\n",
    "    self.l1=nn.Linear(input_size,hidden_size)\n",
    "    self.l2=nn.Linear(hidden_size,hidden_size)\n",
    "    self.l3=nn.Linear(hidden_size,num_classes)\n",
    "    self.relu=nn.ReLU()\n",
    "  def forward(self,x):\n",
    "    out=self.l1(x)\n",
    "    out=self.relu(out)\n",
    "    out=self.l2(out)\n",
    "    out=self.relu(out)\n",
    "    out=self.l3(out)\n",
    "    return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JZ0dhhj9K3HG",
    "outputId": "e368ce56-c1f2-4222-d7d6-9eef02f4661d"
   },
   "outputs": [],
   "source": [
    "# !pip install cuda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "J5l-OVS7Raix",
    "outputId": "fa31220e-d4ff-4d69-f7bc-98e5746b2927"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch (epoch+1)/1000, loss=0.1210\n",
      "epoch (epoch+1)/1000, loss=0.1970\n",
      "epoch (epoch+1)/1000, loss=0.5216\n",
      "epoch (epoch+1)/1000, loss=0.5649\n",
      "epoch (epoch+1)/1000, loss=0.4903\n",
      "epoch (epoch+1)/1000, loss=0.4601\n",
      "epoch (epoch+1)/1000, loss=0.5253\n",
      "epoch (epoch+1)/1000, loss=0.1527\n",
      "epoch (epoch+1)/1000, loss=0.4125\n",
      "epoch (epoch+1)/1000, loss=0.5199\n",
      "epoch (epoch+1)/1000, loss=0.0887\n",
      "epoch (epoch+1)/1000, loss=0.0634\n",
      "epoch (epoch+1)/1000, loss=0.1354\n",
      "epoch (epoch+1)/1000, loss=0.0175\n",
      "epoch (epoch+1)/1000, loss=0.0478\n",
      "epoch (epoch+1)/1000, loss=0.1585\n",
      "epoch (epoch+1)/1000, loss=0.1822\n",
      "epoch (epoch+1)/1000, loss=0.0909\n",
      "epoch (epoch+1)/1000, loss=0.0981\n",
      "epoch (epoch+1)/1000, loss=0.0237\n",
      "epoch (epoch+1)/1000, loss=0.0317\n",
      "epoch (epoch+1)/1000, loss=0.0370\n",
      "epoch (epoch+1)/1000, loss=0.1022\n",
      "epoch (epoch+1)/1000, loss=0.0145\n",
      "epoch (epoch+1)/1000, loss=0.0068\n",
      "epoch (epoch+1)/1000, loss=0.0031\n",
      "epoch (epoch+1)/1000, loss=0.0145\n",
      "epoch (epoch+1)/1000, loss=0.0034\n",
      "epoch (epoch+1)/1000, loss=0.0069\n",
      "epoch (epoch+1)/1000, loss=0.0275\n",
      "epoch (epoch+1)/1000, loss=0.0260\n",
      "epoch (epoch+1)/1000, loss=0.1501\n",
      "epoch (epoch+1)/1000, loss=0.0055\n",
      "epoch (epoch+1)/1000, loss=0.0059\n",
      "epoch (epoch+1)/1000, loss=0.0082\n",
      "epoch (epoch+1)/1000, loss=0.1322\n",
      "epoch (epoch+1)/1000, loss=0.0010\n",
      "epoch (epoch+1)/1000, loss=0.0012\n",
      "epoch (epoch+1)/1000, loss=0.0064\n",
      "epoch (epoch+1)/1000, loss=0.0033\n",
      "epoch (epoch+1)/1000, loss=0.0085\n",
      "epoch (epoch+1)/1000, loss=0.0016\n",
      "epoch (epoch+1)/1000, loss=0.0369\n",
      "epoch (epoch+1)/1000, loss=0.0022\n",
      "epoch (epoch+1)/1000, loss=0.0045\n",
      "epoch (epoch+1)/1000, loss=0.0962\n",
      "epoch (epoch+1)/1000, loss=0.0906\n",
      "epoch (epoch+1)/1000, loss=0.0010\n",
      "epoch (epoch+1)/1000, loss=0.0008\n",
      "epoch (epoch+1)/1000, loss=0.0018\n",
      "epoch (epoch+1)/1000, loss=0.0040\n",
      "epoch (epoch+1)/1000, loss=0.0020\n",
      "epoch (epoch+1)/1000, loss=0.0035\n",
      "epoch (epoch+1)/1000, loss=0.0020\n",
      "epoch (epoch+1)/1000, loss=0.0009\n",
      "epoch (epoch+1)/1000, loss=0.0400\n",
      "epoch (epoch+1)/1000, loss=0.0012\n",
      "epoch (epoch+1)/1000, loss=0.0015\n",
      "epoch (epoch+1)/1000, loss=0.0005\n",
      "epoch (epoch+1)/1000, loss=0.0020\n",
      "epoch (epoch+1)/1000, loss=0.0005\n",
      "epoch (epoch+1)/1000, loss=0.0021\n",
      "epoch (epoch+1)/1000, loss=0.0007\n",
      "epoch (epoch+1)/1000, loss=0.1725\n",
      "epoch (epoch+1)/1000, loss=0.0010\n",
      "epoch (epoch+1)/1000, loss=0.0005\n"
     ]
    }
   ],
   "source": [
    "all_words=[]\n",
    "tags=[]\n",
    "xy=[]\n",
    "for intent in intents['intents']:\n",
    "  tag=intent['tag']\n",
    "  tags.append(tag)\n",
    "  for pattern in intent['patterns']:\n",
    "    w=tokenize(pattern)\n",
    "    all_words.extend(w)\n",
    "    xy.append((w,tag))\n",
    "ignore_words=['?','.','!','.']\n",
    "all_words=[stem(w) for w in all_words if w not in ignore_words]\n",
    "# print(all_words)\n",
    "\n",
    "X_train=[]\n",
    "Y_train=[]\n",
    "for (pattern_sentence,tag) in xy:\n",
    "  bag=bag_of_words(pattern_sentence,all_words)\n",
    "  X_train.append(bag)\n",
    "\n",
    "  label=tags.index(tag)\n",
    "  Y_train.append(label)\n",
    "X_train=np.array(X_train)\n",
    "Y_train=np.array(Y_train)\n",
    "# print(X_train)\n",
    "# print(Y_train)\n",
    "\n",
    "\n",
    "class ChatDataset(Dataset):\n",
    "  def __init__(self):\n",
    "    self.n_samples=len(X_train)\n",
    "    self.x_data=X_train\n",
    "    self.y_data=Y_train\n",
    "\n",
    "\n",
    "  def __getitem__(self,index):\n",
    "    return self.x_data[index],self.y_data[index]\n",
    "\n",
    "  def __len__(self):\n",
    "    return self.n_samples\n",
    "\n",
    "batch_size=8\n",
    "hidden_size=8\n",
    "output_size=len(tags)\n",
    "input_size=len(X_train[0])\n",
    "learning_rate=0.001\n",
    "num_epochs=1000\n",
    "# print(input_size,len(all_words))\n",
    "# print(output_size,tags)\n",
    "dataset=ChatDataset()\n",
    "train_loader=DataLoader(dataset=dataset, batch_size=batch_size,shuffle=True,num_workers=2)\n",
    "\n",
    "\n",
    "device=torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model=NeuralNet(input_size,hidden_size,output_size).to(device)\n",
    "\n",
    "criterion=nn.CrossEntropyLoss()\n",
    "optimizer=torch.optim.Adam(model.parameters(),lr=learning_rate)\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "  for(words,labels) in train_loader:\n",
    "    words=words.to(device)\n",
    "    labels=labels.to(device)\n",
    "\n",
    "    outputs=model(words)\n",
    "    loss=criterion(outputs,labels)\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    if(epoch+1)%100==0:\n",
    "      print(f'epoch (epoch+1)/{num_epochs}, loss={loss.item():.4f}')\n",
    "\n",
    "print(f'final loss, loss={loss.item():.4f}')\n",
    "\n",
    "data = {\n",
    "\"model_state\": model.state_dict(),\n",
    "\"input_size\": input_size,\n",
    "\"hidden_size\": hidden_size,\n",
    "\"output_size\": output_size,\n",
    "\"all_words\": all_words,\n",
    "\"tags\": tags\n",
    "}\n",
    "\n",
    "FILE = \"data.pth\"\n",
    "torch.save(data, FILE)\n",
    "\n",
    "print(f'training complete. file saved to {FILE}')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lRcaFXH4jUcr",
    "outputId": "a8c39beb-42e2-4985-b1f8-1faa6e77f8b7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Let's chat! (type 'quit' to exit)\n",
      "Good to see you again\n",
      "I do not understand...\n",
      "We accept cash as well as online payment\n",
      "Hello, thanks for visiting\n",
      "I do not understand...\n",
      "We accept cash as well as online payment\n",
      "You: quit\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "FILE = \"data.pth\"\n",
    "data = torch.load(FILE)\n",
    "\n",
    "input_size = data[\"input_size\"]\n",
    "hidden_size = data[\"hidden_size\"]\n",
    "output_size = data[\"output_size\"]\n",
    "all_words = data['all_words']\n",
    "tags = data['tags']\n",
    "model_state = data[\"model_state\"]\n",
    "\n",
    "model = NeuralNet(input_size, hidden_size, output_size).to(device)\n",
    "model.load_state_dict(model_state)\n",
    "model.eval()\n",
    "\n",
    "def get_response(msg):\n",
    "    sentence = tokenize(msg)\n",
    "    X = bag_of_words(sentence, all_words)\n",
    "    X = X.reshape(1, X.shape[0])\n",
    "    X = torch.from_numpy(X).to(device)\n",
    "\n",
    "    output = model(X)\n",
    "    _, predicted = torch.max(output, dim=1)\n",
    "\n",
    "    tag = tags[predicted.item()]\n",
    "\n",
    "    probs = torch.softmax(output, dim=1)\n",
    "    prob = probs[0][predicted.item()]\n",
    "    if prob.item() > 0.5:\n",
    "        for intent in intents['intents']:\n",
    "            if tag == intent[\"tag\"]:\n",
    "                return random.choice(intent['responses'])\n",
    "\n",
    "    return \"I do not understand...\"\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"Let's chat! (type 'quit' to exit)\")\n",
    "    while True:\n",
    "        sentence = input(\"You: \")\n",
    "        if sentence == \"quit\":\n",
    "            break\n",
    "\n",
    "        resp = get_response(sentence)\n",
    "        print(resp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "o-vZDs6XMqts",
    "outputId": "ba2a0239-a85a-4491-f7d9-698eddd72729"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'Blog section is for writing original articles and contents to share to the public.'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_response('write blog')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "SsUqNvFhNLtN",
    "outputId": "6a53ba5d-65b3-45b6-dd54-fdbe2ae2dab6"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'We accept payment via khalti'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_response('What are the means of payment')"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
